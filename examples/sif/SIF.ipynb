{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.tsa.api as smt\n",
    "import matplotlib.pyplot as plt\n",
    "from aix360.datasets.SIF_dataset import DataSetTS\n",
    "from aix360.algorithms.sif.SIF_NN import AllRNN, AllLSTM, AllAR\n",
    "from aix360.algorithms.sif.SIF_utils import get_contaminate_series\n",
    "import os\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### model below can be changed to AllLSTM or AllRNN model defined in SIF_NN.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# arma2 model\n",
    "def get_model_train_ar2(data_sets, series, timesteps, w=None, gammas=None, num_train_steps=20000,\n",
    "                        model_dir=None):\n",
    "    initial_learning_rate = 0.01\n",
    "    decay_epochs = [10000, 20000]\n",
    "    batch_size = 20\n",
    "    n_sample = series.shape[1] if len(series.shape) > 1 else 1\n",
    "\n",
    "    # model can be changed to AllLSTM or AllRNN model defined in SIF_NN.py\n",
    "    model = AllAR(\n",
    "        time_steps=timesteps,\n",
    "        x_dim=n_sample,\n",
    "        y_dim=n_sample,\n",
    "        share_param=True,\n",
    "        batch_size=batch_size,\n",
    "        time_series=series,\n",
    "        data_sets=data_sets,\n",
    "        initial_learning_rate=initial_learning_rate,\n",
    "        damping=1e-3,\n",
    "        decay_epochs=decay_epochs,\n",
    "        mini_batch=False,\n",
    "        train_dir='arma_output',\n",
    "        log_dir='logs',\n",
    "        model_name='ar_test',\n",
    "        calc_hessian=False,\n",
    "        w=w,\n",
    "        gammas=gammas,\n",
    "    )\n",
    "    if model_dir is not None:\n",
    "        print('Loading pre-trained model......')\n",
    "        model.restore(model_dir)\n",
    "    else:\n",
    "        model.train(num_steps=num_train_steps, iter_to_switch_to_batch=10, iter_to_switch_to_sgd=10)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### In default, we use the fast mode to accelerate the computation.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "fast_mode = True\n",
    "\n",
    "# parameters\n",
    "timesteps = 2\n",
    "np.random.seed(1)\n",
    "n_sample = 1000\n",
    "n_time_stamp = 100\n",
    "gammas = np.arange(0.0, 0.09, 0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Please ensure that data.pkl and model are downloaded in the following directories."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "data_dir = '../../aix360/data/sif_data/data.pkl'\n",
    "model_dir = '../../aix360/models/sif/ar2'\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Skip generating the synthetic dataset and training the model if using fast-mode. In the fast mode, we directly load the saved dataset and pre-trained model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\lecheng4\\Desktop\\SIF\\aix360\\algorithms\\sif\\SIF_NN.py:18: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n\n",
      "WARNING:tensorflow:From C:\\Users\\lecheng4\\Desktop\\SIF\\aix360\\algorithms\\sif\\SIF.py:28: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n\n",
      "WARNING:tensorflow:From C:\\Users\\lecheng4\\Desktop\\SIF\\aix360\\algorithms\\sif\\SIF_NN.py:38: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\n",
      "WARNING:tensorflow:From C:\\Users\\lecheng4\\Desktop\\SIF\\aix360\\algorithms\\sif\\SIF.py:634: The name tf.squared_difference is deprecated. Please use tf.math.squared_difference instead.\n\n",
      "WARNING:tensorflow:From C:\\Users\\lecheng4\\Desktop\\SIF\\aix360\\algorithms\\sif\\SIF.py:639: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n\n",
      "WARNING:tensorflow:From C:\\Users\\lecheng4\\Anaconda3\\envs\\tf_115\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\lecheng4\\Desktop\\SIF\\aix360\\algorithms\\sif\\SIF.py:642: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n\n",
      "WARNING:tensorflow:From C:\\Users\\lecheng4\\Desktop\\SIF\\aix360\\algorithms\\sif\\SIF.py:644: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n\n",
      "WARNING:tensorflow:From C:\\Users\\lecheng4\\Desktop\\SIF\\aix360\\algorithms\\sif\\SIF.py:95: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n\n",
      "WARNING:tensorflow:From C:\\Users\\lecheng4\\Desktop\\SIF\\aix360\\algorithms\\sif\\SIF.py:599: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n\n",
      "WARNING:tensorflow:From C:\\Users\\lecheng4\\Desktop\\SIF\\aix360\\algorithms\\sif\\SIF.py:610: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n\n",
      "WARNING:tensorflow:From C:\\Users\\lecheng4\\Desktop\\SIF\\aix360\\algorithms\\sif\\SIF.py:103: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n\n",
      "WARNING:tensorflow:From C:\\Users\\lecheng4\\Desktop\\SIF\\aix360\\algorithms\\sif\\SIF.py:160: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n\n",
      "Total number of parameters: 2\nLoading pre-trained model......\nINFO:tensorflow:Restoring parameters from ../../aix360/models/sif/ar2\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "if fast_mode:\n",
    "    assert os.path.exists(data_dir), \"Could not find the data.pkl in {}\".format(data_dir)\n",
    "    # load time series from data.pkl file\n",
    "    series = pickle.load(open(data_dir, \"rb\"))\n",
    "    data_sets = DataSetTS(np.arange(len(series)), np.array(['Y']), None, None, None,\n",
    "                          lag=timesteps).datasets_gen_rnn()\n",
    "    # initialize and train the model which takes the clean time sequence as input and makes prediction\n",
    "    model = get_model_train_ar2(data_sets, series, timesteps, gammas=gammas, model_dir=model_dir)\n",
    "else:\n",
    "    # ar and ma are two parameters controlling the synthetic time sequence data\n",
    "    ar = np.r_[1, -np.array([0.7, -0.3])]\n",
    "    ma = np.r_[1, -np.array([0.1])]\n",
    "\n",
    "    # generate the core process or clean time sequence data\n",
    "    series = [smt.arma_generate_sample(ar, ma, n_time_stamp) for i in range(n_sample)]\n",
    "    series = np.vstack(series)\n",
    "    pickle.dump(series, open(data_dir, \"wb\"))\n",
    "    data_sets = DataSetTS(np.arange(len(series)), np.array(['Y']), None, None, None,\n",
    "                          lag=timesteps).datasets_gen_rnn()\n",
    "    # initialize and train the model which takes the clean time sequence as input and makes prediction\n",
    "    model = get_model_train_ar2(data_sets, series, timesteps, gammas=gammas, model_dir=None)\n",
    "    model.save(model_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### y_contaminate is considered as the contaminating process in the experiment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "y_contaminate = np.random.randn(n_sample)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Insert the contaminated data into the clean time sequence data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "contaminated_series = get_contaminate_series(series, y_contaminate, data_sets.train.labels)\n",
    "\n",
    "# plot contaminated series\n",
    "plt.plot(contaminated_series)\n",
    "plt.savefig('arma')\n",
    "plt.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### compute SIF value"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Regression R-squared: 0.270422\nRegression R-squared: 0.149079\n54.085068464279175 s to compute if_v\n0.0359044075012207 s to compute patchy pred gamma\n0.06781840324401855 s to compute psi_y\nSIF = 166.51340947947648\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# compute SIF value\n",
    "model.update_configure(y_contaminate, gammas)\n",
    "sif = model.get_sif(y_contaminate, timesteps, 1, None, 10, verbose=False)\n",
    "print('SIF = {}'.format(sif))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}